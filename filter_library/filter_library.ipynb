{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\"\"\"\n",
    "This script is used to filter the spectral library generated by MZmine.\n",
    "\n",
    "In the 'input' folder, please prepare three files:\n",
    "1. csv file, which used as MZmine input\n",
    "2. tsv file, which output from MZmine\n",
    "3. mgf file, which output from MZmine\n",
    "The files should have the same name, except for the file extension. (eg, 'library_1.csv', 'library_1.tsv', 'library_1.mgf')\n",
    "\n",
    "The output will be saved in the 'output' folder, containing the filtered mgf and tsv files, ready for GNPS upload.\n",
    "\n",
    "Note: you can have multiple mgf & csv & tsv files in the 'input' folder, the script will process them all.\n",
    "(eg, 'library_1.csv', 'library_1.tsv', 'library_1.mgf', 'library_2.csv', 'library_2.tsv', 'library_2.mgf')\n",
    "\n",
    "\n",
    "Please work in an environment with the following packages installed: numpy, pandas, matchms, molmass\n",
    "\n",
    "@Author: Shipei Xing, Ipsita Mohanty\n",
    "\"\"\"\n",
    "\n",
    "# install the required packages\n",
    "%pip install numpy pandas matchms molmass rdkit"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matchms import Spectrum\n",
    "from matchms.similarity import ModifiedCosine\n",
    "from molmass import Formula\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import rdMolDescriptors\n",
    "\n",
    "def generate_library_df(library_mgf, name_sep='_'):\n",
    "    \"\"\"\n",
    "    Generate metadata dataframe for the mgf file\n",
    "    name_sep: separator for the compound name. eg, 'Phe_CA' -> '_' is the separator\n",
    "    \"\"\"\n",
    "    mgf_file = os.path.join('input', library_mgf)\n",
    "    with open(mgf_file, 'r') as file:\n",
    "        spectrum_list = []\n",
    "        db_idx = 1\n",
    "        for line in file:\n",
    "            # empty line\n",
    "            _line = line.strip()  # remove leading and trailing whitespace\n",
    "            if not _line:\n",
    "                continue\n",
    "            elif line.startswith('BEGIN IONS'):\n",
    "                spectrum = {}\n",
    "                # initialize spectrum\n",
    "                mz_list = []\n",
    "                intensity_list = []\n",
    "            elif line.startswith('END IONS'):\n",
    "                if len(mz_list) == 0:\n",
    "                    continue\n",
    "                spectrum['mz_ls'] = mz_list\n",
    "                spectrum['intensity_ls'] = intensity_list\n",
    "                spectrum['db_idx'] = db_idx\n",
    "                db_idx += 1\n",
    "                spectrum_list.append(spectrum)\n",
    "                continue\n",
    "            else:\n",
    "                # if line contains '=', it is a key-value pair\n",
    "                if '=' in _line:\n",
    "                    # split by first '='\n",
    "                    key, value = _line.split('=', 1)\n",
    "                    spectrum[key] = value\n",
    "                else:\n",
    "                    # if no '=', it is a spectrum pair\n",
    "                    this_mz, this_int = _line.split()\n",
    "                    try:\n",
    "                        mz_list.append(float(this_mz))\n",
    "                        intensity_list.append(float(this_int))\n",
    "                    except:\n",
    "                        continue\n",
    "\n",
    "    df = pd.DataFrame(spectrum_list)\n",
    "\n",
    "    # split adduct by '[' and ']', get the middle part\n",
    "    df['_ADDUCT'] = df['ADDUCT'].apply(lambda x: x.split('[')[1].split(']')[0] if '[' in x else x)\n",
    "\n",
    "    # split name by name_sep\n",
    "    df['_NAME'] = df['NAME'].apply(lambda x: x.split(' (Chimeric')[0] if ' (Chimeric' in x else x)\n",
    "    df['_NAME'] = df['_NAME'].apply(lambda x: x.split('_NCE')[0] if '_NCE' in x else x)\n",
    "    df['NAME_1'] = df['_NAME'].apply(lambda x: x.split(name_sep, 1)[0] if name_sep in x else None)\n",
    "    df['NAME_2'] = df['_NAME'].apply(lambda x: x.split(name_sep, 1)[1] if name_sep in x else None)\n",
    "    df['conjugate'] = df['NAME_2'].apply(lambda x: True if x is not None else False)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def select_library(df, cmpd_df_dict, df_base_name, core_adduct_ls=None, rt_tol=2,\n",
    "                   ms2_tol_da=0.02, prec_intensity_cutoff=10,\n",
    "                   modcos_score_cutoff=0.6, modcos_peak_cutoff=4, cos_score_cutoff=0.95,\n",
    "                   write_df=False):\n",
    "    \"\"\"\n",
    "    Filter the library based on core adduct list, ion dependency, modcos match, and isobaric mass check\n",
    "    if observing one precursor existence beyond prec_intensity_cutoff, remove ones with prec intensity 0.\n",
    "    modcos: either pass the score or the number of matched peaks\n",
    "    \"\"\"\n",
    "    df['selected'] = [True] * df.shape[0]\n",
    "    df['discard_reason'] = [None] * df.shape[0]\n",
    "\n",
    "    ##########################################\n",
    "    # remove doubly charged adduct\n",
    "    _doubly_charged_adducts = df['ADDUCT'].str.contains(r'\\][\\s]*[+]?2|2[+]', regex=True)\n",
    "    df.loc[_doubly_charged_adducts, 'selected'] = False\n",
    "    df.loc[_doubly_charged_adducts, 'discard_reason'] = 'doubly_charged_adduct'\n",
    "\n",
    "    print(f'{df.shape[0]} spectra in the library')\n",
    "    print('After removing doubly charged adducts:')\n",
    "    print(f'{df[\"selected\"].sum()} spectra remaining')\n",
    "    print(f'{len(df[\"NAME\"][df[\"selected\"]].unique())} compounds')\n",
    "\n",
    "    # convert to float\n",
    "    df['RTINSECONDS'] = df['RTINSECONDS'].astype(float)\n",
    "    df['PEPMASS'] = df['PEPMASS'].astype(float)\n",
    "    # bin the RT\n",
    "    df['_RT'] = pd.cut(df['RTINSECONDS'], bins=range(0, int(df['RTINSECONDS'].max()) + 1, rt_tol))\n",
    "    # bin the PEPMASS\n",
    "    df['_PEPMASS'] = df['PEPMASS'].apply(lambda x: round(x, 3))\n",
    "\n",
    "    ##########################################\n",
    "    # filter spectra, indicated by precursor existence\n",
    "    df['cmpd_1_prec_int'] = [None] * df.shape[0]\n",
    "    df['cmpd_2_prec_int'] = [None] * df.shape[0]\n",
    "    df['max_prec_int'] = [0] * df.shape[0]\n",
    "    discarded_scan_ls = precursor_check(df, cmpd_df_dict,\n",
    "                                        ms2_tol_da=ms2_tol_da,\n",
    "                                        prec_intensity_cutoff=prec_intensity_cutoff)\n",
    "    df.loc[df['db_idx'].isin(discarded_scan_ls), 'selected'] = False\n",
    "    df.loc[df['db_idx'].isin(discarded_scan_ls), 'discard_reason'] = 'precursor_check'\n",
    "\n",
    "    print('After precursor existence check:')\n",
    "    print(f'{df[\"selected\"].sum()} spectra remaining')\n",
    "    print(f'{len(df[\"NAME\"][df[\"selected\"]].unique())} compounds')\n",
    "\n",
    "    ##########################################\n",
    "    # core adduct check\n",
    "    discarded_scan_ls, cmpd_adduct_to_be_removed_dict = core_adduct_check(df, core_adduct_ls=core_adduct_ls,\n",
    "                                                                          ms2_tol_da=ms2_tol_da,\n",
    "                                                                          modcos_score_cutoff=modcos_score_cutoff,\n",
    "                                                                          modcos_peak_cutoff=modcos_peak_cutoff)\n",
    "    df.loc[df['db_idx'].isin(discarded_scan_ls), 'selected'] = False\n",
    "    df.loc[df['db_idx'].isin(discarded_scan_ls), 'discard_reason'] = 'core_adduct_check'\n",
    "\n",
    "    print('After adduct check, ion dependency, mod cos match:')\n",
    "    print(f'{df[\"selected\"].sum()} spectra remaining')\n",
    "    print(f'{len(df[\"NAME\"][df[\"selected\"]].unique())} compounds')\n",
    "\n",
    "    ##########################################\n",
    "    # remove spectra, indicated by cmpd_adduct_to_be_removed_dict\n",
    "    df = isobaric_mass_adduct_check(df, cmpd_adduct_to_be_removed_dict)\n",
    "\n",
    "    print('After isobaric mass filter (unique adduct existence):')\n",
    "    print(f'{df[\"selected\"].sum()} spectra selected')\n",
    "    print(f'{len(df[\"NAME\"][df[\"selected\"]].unique())} compounds')\n",
    "\n",
    "    ##########################################\n",
    "    # remove almost identical spectra\n",
    "    df = remove_identical_spectra(df, ms2_tol_da=ms2_tol_da, cos_score_cutoff=cos_score_cutoff)\n",
    "\n",
    "    print('After removing almost identical spectra:')\n",
    "    print(f'{df[\"selected\"].sum()} spectra selected')\n",
    "    print(f'{len(df[\"NAME\"][df[\"selected\"]].unique())} compounds')\n",
    "\n",
    "    if write_df:\n",
    "        file_path = os.path.join('output', 'library_metadata')\n",
    "        file_path = os.path.join(file_path, f'{df_base_name}_metadata.tsv')\n",
    "        df.to_csv(file_path, sep='\\t', index=False)\n",
    "\n",
    "    # remove cols\n",
    "    df = df.drop(['_ADDUCT', '_NAME', 'db_idx', '_RT', 'NAME_1', 'NAME_2', 'conjugate', '_PEPMASS', 'cmpd_1_prec_int',\n",
    "                  'cmpd_2_prec_int', 'max_prec_int', 'discard_reason'], axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def remove_identical_spectra(df, ms2_tol_da=0.02, cos_score_cutoff=0.95):\n",
    "    \"\"\"\n",
    "    Remove almost identical spectra\n",
    "    \"\"\"\n",
    "    # sort df by NAME and ADDUCT\n",
    "    df = df.sort_values(['NAME', 'ADDUCT'])\n",
    "\n",
    "    # Group by NAME and ADDUCT\n",
    "    for (name, adduct), group in df.groupby(['NAME', 'ADDUCT']):\n",
    "        # Sort group by precursor_purity from high to low\n",
    "        group = group.sort_values('PRECURSOR_PURITY', ascending=False).reset_index(drop=True)\n",
    "\n",
    "        for i in range(1, len(group)):\n",
    "            if group.loc[i, 'selected']:\n",
    "                for j in range(i):\n",
    "                    if group.loc[j, 'selected']:\n",
    "                        # Compare spectra\n",
    "                        score = compare_spectra_cos(group.iloc[j], group.iloc[i], ms2_tol_da)\n",
    "                        if score > cos_score_cutoff:\n",
    "                            group.loc[i, 'selected'] = False\n",
    "                            group.loc[i, 'discard_reason'] = 'almost_identical_spectrum'\n",
    "                            break\n",
    "\n",
    "        # Update the original DataFrame\n",
    "        df.loc[group.index, 'selected'] = group['selected']\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def compare_spectra_cos(spec1, spec2, ms2_tol_da=0.02):\n",
    "    \"\"\"\n",
    "    Compare two spectra using cosine similarity\n",
    "    \"\"\"\n",
    "    # Create Spectrum objects\n",
    "    spectrum1 = Spectrum(mz=np.array(spec1['mz_ls']),\n",
    "                         intensities=np.array(spec1['intensity_ls']),\n",
    "                         metadata={'precursor_mz': spec1['PEPMASS']})\n",
    "    spectrum2 = Spectrum(mz=np.array(spec2['mz_ls']),\n",
    "                         intensities=np.array(spec2['intensity_ls']),\n",
    "                         metadata={'precursor_mz': spec2['PEPMASS']})\n",
    "\n",
    "    # Calculate cosine similarity\n",
    "    cos_greedy = CosineGreedy(tolerance=ms2_tol_da)\n",
    "    score = cos_greedy.pair(spectrum1, spectrum2)\n",
    "\n",
    "    return score['score']\n",
    "\n",
    "\n",
    "def write_to_mgf(df, out_mgf):\n",
    "    \"\"\"\n",
    "    Write the selected library to a new mgf file\n",
    "    \"\"\"\n",
    "    df = df[df['selected']].reset_index(drop=True)\n",
    "    # remove cols\n",
    "    df = df.drop(['selected', 'OTHER_MATCHED_COMPOUNDS', 'OTHER_MATCHED_COMPOUNDS_NAMES', 'SPECTYPE'], axis=1)\n",
    "    # move cols mz_ls and intensity_ls to the end\n",
    "    df = df[[col for col in df.columns if col not in ['Num peaks', 'mz_ls', 'intensity_ls']] + ['Num peaks', 'mz_ls',\n",
    "                                                                                                'intensity_ls']]\n",
    "\n",
    "    with open(out_mgf, 'w') as file:\n",
    "        # scan_idx = 1\n",
    "        for idx, row in df.iterrows():\n",
    "            file.write('BEGIN IONS\\n')\n",
    "            for key, value in row.items():\n",
    "                if key == 'mz_ls':\n",
    "                    for mz, intensity in zip(row['mz_ls'], row['intensity_ls']):\n",
    "                        file.write(f'{mz} {intensity}\\n')\n",
    "                elif key == 'intensity_ls':\n",
    "                    continue\n",
    "                # elif key == 'SCANS':\n",
    "                #     file.write(f'SCANS={scan_idx}\\n')\n",
    "                # elif key == 'FEATURE_ID':\n",
    "                #     file.write(f'FEATURE_ID={value}\\n')\n",
    "                else:\n",
    "                    file.write(f'{key}={value}\\n')\n",
    "            file.write('END IONS\\n\\n')\n",
    "            # scan_idx += 1\n",
    "\n",
    "\n",
    "def write_tsv(df, library_tsv, out_tsv):\n",
    "    \"\"\"\n",
    "    Write the selected library to a new tsv file, for library generation on GNPS\n",
    "    \"\"\"\n",
    "    file_path = os.path.join('input', library_tsv)\n",
    "    lib_tsv = pd.read_csv(file_path, sep='\\t')\n",
    "\n",
    "    # all SCANs selected\n",
    "    selected_scans = df[df['selected']]['SCANS'].tolist()\n",
    "\n",
    "    # reserve lib_tsv with selected scans in 'EXTRACTSCAN' column\n",
    "    lib_tsv = lib_tsv[lib_tsv['EXTRACTSCAN'].astype(str).isin(selected_scans)]\n",
    "\n",
    "    # # fill 'EXTRACTSCAN' column with 1 to length of lib_tsv\n",
    "    # lib_tsv['EXTRACTSCAN'] = range(1, lib_tsv.shape[0] + 1)\n",
    "\n",
    "    # FILENAME\n",
    "    lib_tsv['FILENAME'] = lib_tsv['FILENAME'].apply(lambda x: x.split('.mgf')[0] + '_filtered.mgf')\n",
    "\n",
    "    lib_tsv.to_csv(out_tsv, sep='\\t', index=False, na_rep='N/A')\n",
    "\n",
    "\n",
    "def precursor_check(df, cmpd_df_dict, ms2_tol_da, prec_intensity_cutoff=10):\n",
    "    \"\"\"\n",
    "    precursor existence check\n",
    "    this is to remove the spectra that are labeled incorrectly (one spectrum being selected multiple times)\n",
    "    \"\"\"\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        if not row['selected']:\n",
    "            continue\n",
    "        if not row['conjugate']:\n",
    "            continue\n",
    "        if row['OTHER_MATCHED_COMPOUNDS'] is None:\n",
    "            continue\n",
    "\n",
    "        # get the precursor mz M+H of the two compounds\n",
    "        cmpd_1_prec_mz = cmpd_df_dict.get(row['NAME_1'])\n",
    "        cmpd_2_prec_mz = cmpd_df_dict.get(row['NAME_2'])\n",
    "        cmpd_1_prec_int = 0\n",
    "        cmpd_2_prec_int = 0\n",
    "        if cmpd_1_prec_mz:\n",
    "            mz_idx = np.argmin(np.abs(np.array(row['mz_ls']) - cmpd_1_prec_mz))\n",
    "            if np.abs(row['mz_ls'][mz_idx] - cmpd_1_prec_mz) <= ms2_tol_da:\n",
    "                cmpd_1_prec_int = row['intensity_ls'][mz_idx]\n",
    "                df.loc[idx, 'cmpd_1_prec_int'] = cmpd_1_prec_int\n",
    "        if cmpd_2_prec_mz:\n",
    "            mz_idx = np.argmin(np.abs(np.array(row['mz_ls']) - cmpd_2_prec_mz))\n",
    "            if np.abs(row['mz_ls'][mz_idx] - cmpd_2_prec_mz) <= ms2_tol_da:\n",
    "                cmpd_2_prec_int = row['intensity_ls'][mz_idx]\n",
    "                df.loc[idx, 'cmpd_2_prec_int'] = cmpd_2_prec_int\n",
    "\n",
    "        df.loc[idx, 'max_prec_int'] = max(cmpd_1_prec_int, cmpd_2_prec_int)\n",
    "\n",
    "    # sort df by _RT and _PEPMASS\n",
    "    df = df.sort_values(['_RT', '_PEPMASS'])\n",
    "    df['_PEPMASS'] = df['_PEPMASS'].astype(str)\n",
    "\n",
    "    _df = df[df['conjugate']]\n",
    "    discarded_scan_ls = []\n",
    "    for binned_rt in _df['_RT'].unique():\n",
    "        subdf = _df[_df['_RT'] == binned_rt]\n",
    "        # choose a subdf with the same precursor mz\n",
    "        for prec_mz in subdf['_PEPMASS'].unique():\n",
    "            _subdf = subdf[subdf['_PEPMASS'] == prec_mz]\n",
    "\n",
    "            if len(_subdf) == 1:\n",
    "                continue\n",
    "\n",
    "            # different compounds\n",
    "            if len(_subdf['_NAME'].unique()) == 1:\n",
    "                continue\n",
    "\n",
    "            # maximum precursor intensity\n",
    "            if _subdf['max_prec_int'].max() < prec_intensity_cutoff:\n",
    "                continue\n",
    "\n",
    "            # if multiple, sort by max_prec_int\n",
    "            _subdf = _subdf.sort_values('max_prec_int', ascending=False)\n",
    "\n",
    "            to_discard = _subdf[_subdf['max_prec_int'] == 0]['db_idx'].tolist()\n",
    "            discarded_scan_ls.extend(to_discard)\n",
    "\n",
    "    return discarded_scan_ls\n",
    "\n",
    "\n",
    "def core_adduct_check(df, core_adduct_ls=None,\n",
    "                      ms2_tol_da=0.05, modcos_score_cutoff=0.6, modcos_peak_cutoff=4):\n",
    "    df = df[df['selected']].copy()\n",
    "    # get the unique molecules\n",
    "    unique_smiles = df['SMILES'].unique().tolist()\n",
    "    # list of selected scan numbers\n",
    "    discarded_scan_ls = []\n",
    "    cmpd_adduct_to_be_removed_dict = {}  # key: RT, value: cmpd_adduct_to_be_removed\n",
    "    # filter the library by (SMILES, _RT)\n",
    "    for smiles in unique_smiles:\n",
    "        sub_df = df[(df['SMILES'] == smiles)]\n",
    "        for binned_rt in sub_df['_RT'].unique():\n",
    "            _subdf = sub_df[sub_df['_RT'] == binned_rt]\n",
    "\n",
    "            # check the subdf\n",
    "            scan_ls, cmpd_adduct_to_be_removed = subdf_check(_subdf, core_adduct_ls=core_adduct_ls,\n",
    "                                                             ms2_tol_da=ms2_tol_da,\n",
    "                                                             modcos_score_cutoff=modcos_score_cutoff,\n",
    "                                                             modcos_peak_cutoff=modcos_peak_cutoff)\n",
    "            discarded_scan_ls.extend(scan_ls)\n",
    "            if cmpd_adduct_to_be_removed:\n",
    "                cmpd_adduct_to_be_removed_dict[binned_rt] = cmpd_adduct_to_be_removed\n",
    "\n",
    "    return discarded_scan_ls, cmpd_adduct_to_be_removed_dict\n",
    "\n",
    "\n",
    "def subdf_check(df, core_adduct_ls=None,\n",
    "                ms2_tol_da=0.05, modcos_score_cutoff=0.6, modcos_peak_cutoff=4):\n",
    "    \"\"\"\n",
    "    check the dataframe for one molecule\n",
    "    :return: a list of selected scan numbers, a list of compound:adduct to be removed\n",
    "    \"\"\"\n",
    "    if core_adduct_ls is None:\n",
    "        core_adduct_ls = ['M+H', 'M-H2O+H', 'M+NH4', 'M-2H2O+H', 'M-H2O+NH4', 'M-2H2O+NH4',\n",
    "                          '2M+H', '2M-H2O+H', '2M+NH4', '2M-2H2O+H', '2M-H2O+NH4', '2M-2H2O+NH4',\n",
    "                          'M-H', 'M+2H', 'M-H2O+2H', 'M-2H2O+2H']\n",
    "\n",
    "    # create a ModifiedCosine object\n",
    "    modified_cosine = ModifiedCosine(tolerance=ms2_tol_da)\n",
    "\n",
    "    subdf = df.copy()\n",
    "    # check the core adducts, if any adduct in the core_adduct_ls is in the library\n",
    "    subdf['core_adduct'] = subdf['_ADDUCT'].map(lambda x: x in core_adduct_ls)\n",
    "\n",
    "    # if no core adducts are found, return empty list\n",
    "    if not subdf['core_adduct'].any():\n",
    "        # print('No core adducts found: ', subdf['NAME'].iloc[0], '   Found adducts: ',\n",
    "        #       subdf['_ADDUCT'].unique().tolist())\n",
    "        return subdf['db_idx'].tolist(), []\n",
    "\n",
    "    # select the spectra with core adducts\n",
    "    core_df = subdf[subdf['core_adduct']].copy()\n",
    "    # sort by core_adduct_ls\n",
    "    core_df['core_adduct'] = core_df['_ADDUCT'].map(lambda x: core_adduct_ls.index(x))\n",
    "    core_df = core_df.sort_values('core_adduct')\n",
    "    # get all core spectra\n",
    "    core_spec_ls = []\n",
    "    for idx, row in core_df.iterrows():\n",
    "        core_spec = Spectrum(mz=np.array(row['mz_ls']),\n",
    "                             intensities=np.array(row['intensity_ls']),\n",
    "                             metadata={'precursor_mz': row['PEPMASS'],\n",
    "                                       'adduct': row['_ADDUCT']})\n",
    "        core_spec_ls.append(core_spec)\n",
    "\n",
    "    unique_adducts = subdf['_ADDUCT'].unique().tolist()\n",
    "    # check the adduct dependency\n",
    "    if len(unique_adducts) > 1:\n",
    "        allowed_adducts = unique_adducts.copy()\n",
    "        if 'M-H2O+Na' in unique_adducts and 'M-H2O+H' not in unique_adducts:\n",
    "            allowed_adducts.remove('M-H2O+Na')\n",
    "            if 'M-2H2O+Na' in allowed_adducts:\n",
    "                allowed_adducts.remove('M-2H2O+Na')\n",
    "            if 'M-3H2O+Na' in allowed_adducts:\n",
    "                allowed_adducts.remove('M-3H2O+Na')\n",
    "        if 'M-H2O+K' in unique_adducts and 'M-H2O+H' not in unique_adducts:\n",
    "            allowed_adducts.remove('M-H2O+K')\n",
    "            if 'M-2H2O+K' in allowed_adducts:\n",
    "                allowed_adducts.remove('M-2H2O+K')\n",
    "            if 'M-3H2O+K' in allowed_adducts:\n",
    "                allowed_adducts.remove('M-3H2O+K')\n",
    "        if 'M-2H2O+Na' in unique_adducts and 'M-H2O+Na' not in unique_adducts and 'M-2H2O+H' in unique_adducts:\n",
    "            allowed_adducts.remove('M-2H2O+Na')\n",
    "            if 'M-3H2O+Na' in allowed_adducts:\n",
    "                allowed_adducts.remove('M-3H2O+Na')\n",
    "        if 'M-2H2O+K' in unique_adducts and 'M-H2O+K' not in unique_adducts and 'M-2H2O+H' in unique_adducts:\n",
    "            allowed_adducts.remove('M-2H2O+K')\n",
    "            if 'M-3H2O+K' in allowed_adducts:\n",
    "                allowed_adducts.remove('M-3H2O+K')\n",
    "        if 'M-3H2O+Na' in unique_adducts and 'M-2H2O+Na' not in unique_adducts and 'M-3H2O+H' in unique_adducts:\n",
    "            allowed_adducts.remove('M-3H2O+Na')\n",
    "        if 'M-3H2O+K' in unique_adducts and 'M-2H2O+K' not in unique_adducts and 'M-3H2O+H' in unique_adducts:\n",
    "            allowed_adducts.remove('M-3H2O+K')\n",
    "        if 'M-2H2O+H' in unique_adducts and 'M-H2O+H' not in unique_adducts and 'M+H' in unique_adducts:\n",
    "            allowed_adducts.remove('M-2H2O+H')\n",
    "            if 'M-3H2O+H' in allowed_adducts:\n",
    "                allowed_adducts.remove('M-3H2O+H')\n",
    "        if 'M-3H2O+H' in unique_adducts and 'M-2H2O+H' not in unique_adducts and 'M+H' in unique_adducts:\n",
    "            allowed_adducts.remove('M-3H2O+H')\n",
    "\n",
    "        if 'M-2H2O+2H' in unique_adducts and 'M-H2O+2H' not in unique_adducts and 'M+2H' in unique_adducts:\n",
    "            allowed_adducts.remove('M-2H2O+2H')\n",
    "            if 'M-3H2O+2H' in allowed_adducts:\n",
    "                allowed_adducts.remove('M-3H2O+2H')\n",
    "        if 'M-3H2O+2H' in unique_adducts and 'M-2H2O+2H' not in unique_adducts and 'M+2H' in unique_adducts:\n",
    "            allowed_adducts.remove('M-3H2O+2H')\n",
    "\n",
    "        if 'M-2H2O+NH4' in unique_adducts and 'M-H2O+NH4' not in unique_adducts and 'M-2H2O+H' not in unique_adducts:\n",
    "            allowed_adducts.remove('M-2H2O+NH4')\n",
    "            if 'M-3H2O+NH4' in allowed_adducts:\n",
    "                allowed_adducts.remove('M-3H2O+NH4')\n",
    "        if 'M-3H2O+NH4' in unique_adducts and 'M-2H2O+NH4' not in unique_adducts and 'M-3H2O+H' not in unique_adducts:\n",
    "            allowed_adducts.remove('M-3H2O+NH4')\n",
    "\n",
    "        if '2M-H2O+Na' in unique_adducts and '2M-H2O+H' not in unique_adducts:\n",
    "            allowed_adducts.remove('2M-H2O+Na')\n",
    "            if '2M-2H2O+Na' in allowed_adducts:\n",
    "                allowed_adducts.remove('2M-2H2O+Na')\n",
    "            if '2M-3H2O+Na' in allowed_adducts:\n",
    "                allowed_adducts.remove('2M-3H2O+Na')\n",
    "        if '2M-H2O+K' in unique_adducts and '2M-H2O+H' not in unique_adducts:\n",
    "            allowed_adducts.remove('2M-H2O+K')\n",
    "            if '2M-2H2O+K' in allowed_adducts:\n",
    "                allowed_adducts.remove('2M-2H2O+K')\n",
    "            if '2M-3H2O+K' in allowed_adducts:\n",
    "                allowed_adducts.remove('2M-3H2O+K')\n",
    "        if '2M-2H2O+Na' in unique_adducts and '2M-H2O+Na' not in unique_adducts and '2M-2H2O+H' in unique_adducts:\n",
    "            allowed_adducts.remove('2M-2H2O+Na')\n",
    "            if '2M-3H2O+Na' in allowed_adducts:\n",
    "                allowed_adducts.remove('2M-3H2O+Na')\n",
    "        if '2M-2H2O+K' in unique_adducts and '2M-H2O+K' not in unique_adducts and '2M-2H2O+H' in unique_adducts:\n",
    "            allowed_adducts.remove('2M-2H2O+K')\n",
    "            if '2M-3H2O+K' in allowed_adducts:\n",
    "                allowed_adducts.remove('2M-3H2O+K')\n",
    "        if '2M-3H2O+Na' in unique_adducts and '2M-2H2O+Na' not in unique_adducts and '2M-3H2O+H' in unique_adducts:\n",
    "            allowed_adducts.remove('2M-3H2O+Na')\n",
    "        if '2M-3H2O+K' in unique_adducts and '2M-2H2O+K' not in unique_adducts and '2M-3H2O+H' in unique_adducts:\n",
    "            allowed_adducts.remove('2M-3H2O+K')\n",
    "        if '2M-2H2O+H' in unique_adducts and '2M-H2O+H' not in unique_adducts and '2M+H' in unique_adducts:\n",
    "            allowed_adducts.remove('2M-2H2O+H')\n",
    "            if '2M-3H2O+H' in allowed_adducts:\n",
    "                allowed_adducts.remove('2M-3H2O+H')\n",
    "        if '2M-3H2O+H' in unique_adducts and '2M-2H2O+H' not in unique_adducts and '2M+H' in unique_adducts:\n",
    "            allowed_adducts.remove('2M-3H2O+H')\n",
    "\n",
    "        if '2M-2H2O+2H' in unique_adducts and '2M-H2O+2H' not in unique_adducts and '2M+2H' in unique_adducts:\n",
    "            allowed_adducts.remove('2M-2H2O+2H')\n",
    "            if '2M-3H2O+2H' in allowed_adducts:\n",
    "                allowed_adducts.remove('2M-3H2O+2H')\n",
    "        if '2M-3H2O+2H' in unique_adducts and '2M-2H2O+2H' not in unique_adducts and '2M+2H' in unique_adducts:\n",
    "            allowed_adducts.remove('2M-3H2O+2H')\n",
    "\n",
    "        if '2M-2H2O+NH4' in unique_adducts and '2M-H2O+NH4' not in unique_adducts and '2M-2H2O+H' not in unique_adducts:\n",
    "            allowed_adducts.remove('2M-2H2O+NH4')\n",
    "            if '2M-3H2O+NH4' in allowed_adducts:\n",
    "                allowed_adducts.remove('2M-3H2O+NH4')\n",
    "        if '2M-3H2O+NH4' in unique_adducts and '2M-2H2O+NH4' not in unique_adducts and '2M-3H2O+H' not in unique_adducts:\n",
    "            allowed_adducts.remove('2M-3H2O+NH4')\n",
    "\n",
    "        subdf['selected'] = subdf['_ADDUCT'].map(lambda x: x in allowed_adducts)\n",
    "\n",
    "        # for unselected spectra, calculate the scores for different adducts\n",
    "        for idx, row in subdf.iterrows():\n",
    "            if not row['selected']:\n",
    "                this_spec = Spectrum(mz=np.array(row['mz_ls']),\n",
    "                                     intensities=np.array(row['intensity_ls']),\n",
    "                                     metadata={'precursor_mz': row['PEPMASS'],\n",
    "                                               'adduct': row['_ADDUCT']})\n",
    "                # calculate the ModifiedCosine score\n",
    "                for core_spec in core_spec_ls:\n",
    "                    if core_spec.get('adduct') == this_spec.get('adduct'):\n",
    "                        continue\n",
    "                    score = modified_cosine.pair(core_spec, this_spec)\n",
    "                    if score['score'] >= modcos_score_cutoff or score['matches'] >= modcos_peak_cutoff:\n",
    "                        subdf.loc[idx, 'selected'] = True\n",
    "                        break\n",
    "\n",
    "        # use spectrum with unambiguous compound to filter out the ambiguous ones\n",
    "        cmpd_adduct_to_be_removed = None\n",
    "        _subdf = subdf[(subdf['selected']) & (subdf['OTHER_MATCHED_COMPOUNDS'].isna())]\n",
    "        if len(_subdf) > 0:\n",
    "            cmpd_adduct_to_be_removed = subdf['OTHER_MATCHED_COMPOUNDS_NAMES'].tolist()\n",
    "            # remove nan\n",
    "            cmpd_adduct_to_be_removed = [x for x in cmpd_adduct_to_be_removed if str(x) != 'nan']\n",
    "            # remove empty string\n",
    "            cmpd_adduct_to_be_removed = [x for x in cmpd_adduct_to_be_removed if x]\n",
    "            # split by ';' and flatten the list\n",
    "            cmpd_adduct_to_be_removed = [x.split(';') for x in cmpd_adduct_to_be_removed]\n",
    "            cmpd_adduct_to_be_removed = [item for sublist in cmpd_adduct_to_be_removed for item in sublist]\n",
    "\n",
    "        # db_idx of the discarded spectra\n",
    "        discarded_scan_no_ls = subdf[~subdf['selected']]['db_idx'].tolist()\n",
    "        return discarded_scan_no_ls, cmpd_adduct_to_be_removed\n",
    "    else:\n",
    "        return [], None\n",
    "\n",
    "\n",
    "def isobaric_mass_adduct_check(df, cmpd_adduct_to_be_removed_dict):\n",
    "    \"\"\"\n",
    "    isobaric mass filter, based on unique adduct existence\n",
    "    \"\"\"\n",
    "    if cmpd_adduct_to_be_removed_dict:\n",
    "        for binned_rt, cmpd_adduct_to_be_removed in cmpd_adduct_to_be_removed_dict.items():\n",
    "            for cmpd_adduct in cmpd_adduct_to_be_removed:\n",
    "                name, adduct, _ = cmpd_adduct.split(':')\n",
    "                row_idx = df[\n",
    "                    (df['_RT'] == binned_rt) & (df['NAME'] == name.strip()) & (df['ADDUCT'] == adduct.strip())].index\n",
    "                if len(row_idx) > 0:\n",
    "                    df.loc[row_idx, 'selected'] = False\n",
    "                    df.loc[row_idx, 'discard_reason'] = 'isobaric_mass_adduct_check'\n",
    "    return df\n",
    "\n",
    "\n",
    "def preprocess_cmpd_df(library_csv):\n",
    "    \"\"\"\n",
    "    Preprocess the compound dataframe, return a dictionary of compound name to precursor mass (M+H)\n",
    "    \"\"\"\n",
    "    file_path = os.path.join('input', library_csv)\n",
    "    cmpd_df = pd.read_csv(file_path)\n",
    "\n",
    "    # rename column 'SMILES' to 'smiles'\n",
    "    if 'SMILES' in cmpd_df.columns:\n",
    "        cmpd_df = cmpd_df.rename(columns={'SMILES': 'smiles'})\n",
    "\n",
    "    # check if 'formula' column exists\n",
    "    if 'formula' not in cmpd_df.columns:\n",
    "        print('formula column missing, converting SMILES to formula')\n",
    "        cmpd_df['formula'] = cmpd_df['smiles'].apply(smiles_to_formula)\n",
    "\n",
    "    cmpd_df['prec_mz'] = cmpd_df['formula'].apply(calc_prec_mz)\n",
    "\n",
    "    # dictionary of mapping name to precursor mass\n",
    "    cmpd_df_dict = cmpd_df.set_index('compound_name')['prec_mz'].to_dict()\n",
    "\n",
    "    return cmpd_df_dict\n",
    "\n",
    "\n",
    "def smiles_to_formula(smiles):\n",
    "    # Convert SMILES to a molecule object\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "\n",
    "    if mol:\n",
    "        # Get the molecular formula\n",
    "        formula = rdMolDescriptors.CalcMolFormula(mol)\n",
    "        return formula\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def calc_prec_mz(formula):\n",
    "    \"\"\"\n",
    "    Calculate the precursor mass (M+H) for a given formula string\n",
    "    \"\"\"\n",
    "    try:\n",
    "        f = Formula(formula)\n",
    "        return f.monoisotopic_mass + 1.007276\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "\n",
    "def main(name_sep='_'):\n",
    "    # create the output folder\n",
    "    if not os.path.exists('output'):\n",
    "        os.makedirs('output')\n",
    "\n",
    "    metadata_folder = os.path.join('output', 'library_metadata')\n",
    "    if not os.path.exists(metadata_folder):\n",
    "        os.makedirs(metadata_folder)\n",
    "\n",
    "    # list all the files in the input folder\n",
    "    all_files = os.listdir('input')\n",
    "    # filter the mgf files\n",
    "    library_mgfs = [x for x in all_files if x.endswith('.mgf')]\n",
    "\n",
    "    for library_mgf in library_mgfs:\n",
    "        print(f'Processing {library_mgf}')\n",
    "\n",
    "        base_name = library_mgf.split('.mgf')[0]\n",
    "\n",
    "        # check the existence of the .tsv\n",
    "        library_tsv = base_name + '.tsv'\n",
    "        file_path = os.path.join('input', library_tsv)\n",
    "        if not os.path.exists(file_path):\n",
    "            print(f'tsv file missing: {library_tsv} does not exist')\n",
    "            continue\n",
    "\n",
    "        # check the existence of the .csv\n",
    "        library_csv = base_name + '.csv'\n",
    "        file_path = os.path.join('input', library_csv)\n",
    "        if not os.path.exists(file_path):\n",
    "            print(f'csv file missing: {library_csv} does not exist')\n",
    "            continue\n",
    "        cmpd_df_dict = preprocess_cmpd_df(library_csv)\n",
    "\n",
    "        # main process\n",
    "        df = generate_library_df(library_mgf, name_sep)\n",
    "        df = select_library(df, cmpd_df_dict, base_name,\n",
    "                            rt_tol=2, ms2_tol_da=0.02, prec_intensity_cutoff=10,\n",
    "                            modcos_score_cutoff=0.6, modcos_peak_cutoff=4,\n",
    "                            cos_score_cutoff=0.95,\n",
    "                            write_df=True)\n",
    "\n",
    "        out_mgf = os.path.join('output', base_name + '_filtered.mgf')\n",
    "        write_to_mgf(df, out_mgf)\n",
    "        out_tsv = os.path.join('output', base_name + '_filtered.tsv')\n",
    "        write_tsv(df, library_tsv, out_tsv)\n"
   ],
   "id": "701614cc1dbcc01d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# run the main function\n",
    "main()"
   ],
   "id": "374cc90af3812d6a",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T01:41:00.890653Z",
     "start_time": "2024-05-02T01:40:59.228841Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create the 'input' folder, and put the library mgf files and tsv files in the folder\n",
    "# the mgf files should have the same name as the tsv files"
   ],
   "id": "ce7bbfaa79c739b2",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T20:19:35.098839Z",
     "start_time": "2024-05-06T20:19:35.085847Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from molmass import Formula\n",
    "from matchms import Spectrum\n",
    "from matchms.similarity import ModifiedCosine"
   ],
   "id": "2f7cae1cecffebc7",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T20:19:35.850400Z",
     "start_time": "2024-05-06T20:19:35.815114Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# import some functions, just run this cell\n",
    "\n",
    "def generate_library_df(library_mgf, name_sep):\n",
    "    \"\"\"\n",
    "    Generate metadata dataframe for the mgf file\n",
    "    name_sep: separator for the compound name. eg, 'Phe_CA' -> '_' is the separator\n",
    "    \"\"\"\n",
    "    with open(f'input/{library_mgf}', 'r') as file:\n",
    "        spectrum_list = []\n",
    "        db_idx = 1\n",
    "        for line in file:\n",
    "            # empty line\n",
    "            _line = line.strip()  # remove leading and trailing whitespace\n",
    "            if not _line:\n",
    "                continue\n",
    "            elif line.startswith('BEGIN IONS'):\n",
    "                spectrum = {}\n",
    "                # initialize spectrum\n",
    "                mz_list = []\n",
    "                intensity_list = []\n",
    "            elif line.startswith('END IONS'):\n",
    "                if len(mz_list) == 0:\n",
    "                    continue\n",
    "                spectrum['mz_ls'] = mz_list\n",
    "                spectrum['intensity_ls'] = intensity_list\n",
    "                spectrum['db_idx'] = db_idx\n",
    "                db_idx += 1\n",
    "                spectrum_list.append(spectrum)\n",
    "                continue\n",
    "            else:\n",
    "                # if line contains '=', it is a key-value pair\n",
    "                if '=' in _line:\n",
    "                    # split by first '='\n",
    "                    key, value = _line.split('=', 1)\n",
    "                    spectrum[key] = value\n",
    "                else:\n",
    "                    # if no '=', it is a spectrum pair\n",
    "                    this_mz, this_int = _line.split()\n",
    "                    try:\n",
    "                        mz_list.append(float(this_mz))\n",
    "                        intensity_list.append(float(this_int))\n",
    "                    except:\n",
    "                        continue\n",
    "\n",
    "    df = pd.DataFrame(spectrum_list)\n",
    "\n",
    "    # split adduct by '[' and ']', get the middle part\n",
    "    df['_ADDUCT'] = df['ADDUCT'].apply(lambda x: x.split('[')[1].split(']')[0] if '[' in x else x)\n",
    "\n",
    "    # split name by name_sep\n",
    "    df['_NAME'] = df['NAME'].apply(lambda x: x.split(' (Chimeric')[0] if ' (Chimeric' in x else x)\n",
    "    df['_NAME'] = df['_NAME'].apply(lambda x: x.split('_NCE')[0] if '_NCE' in x else x)\n",
    "    df['NAME_1'] = df['_NAME'].apply(lambda x: x.split(name_sep)[0] if name_sep in x else None)\n",
    "    df['NAME_2'] = df['_NAME'].apply(lambda x: x.split(name_sep)[1] if name_sep in x else None)\n",
    "    df['conjugate'] = df['NAME_2'].apply(lambda x: True if x is not None else False)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def select_library(df, cmpd_df_dict, core_adduct_ls=None,\n",
    "                   ms2_tol_da=0.02, prec_intensity_cutoff=10,\n",
    "                   modcos_score_cutoff=0.6, modcos_peak_cutoff=4,\n",
    "                   write_df=False):\n",
    "    \"\"\"\n",
    "    Filter the library based on core adduct list, ion dependency, modcos match, and isobaric mass check\n",
    "    if observing one precursor existence beyond prec_intensity_cutoff, remove ones with prec intensity 0.\n",
    "    modcos: either pass the score or the number of matched peaks\n",
    "    \"\"\"\n",
    "    df['selected'] = [True] * df.shape[0]\n",
    "    df['discard_reason'] = [None] * df.shape[0]\n",
    "\n",
    "    # convert to float\n",
    "    df['RTINSECONDS'] = df['RTINSECONDS'].astype(float)\n",
    "    df['PEPMASS'] = df['PEPMASS'].astype(float)\n",
    "    # bin the RT\n",
    "    df['_RT'] = df['RTINSECONDS'].apply(lambda x: round(x, 2))\n",
    "    # bin the PEPMASS\n",
    "    df['_PEPMASS'] = df['PEPMASS'].apply(lambda x: round(x, 3))\n",
    "\n",
    "    # filter spectra, indicated by precursor existence\n",
    "    discarded_scan_ls = precursor_check(df, cmpd_df_dict,\n",
    "                                        ms2_tol_da=ms2_tol_da,\n",
    "                                        prec_intensity_cutoff=prec_intensity_cutoff)\n",
    "    df.loc[df['db_idx'].isin(discarded_scan_ls), 'selected'] = False\n",
    "    df.loc[df['db_idx'].isin(discarded_scan_ls), 'discard_reason'] = 'precursor_check'\n",
    "\n",
    "    print(f'{df.shape[0]} spectra in the library')\n",
    "    print('After precursor existence check:')\n",
    "    print(f'{df[\"selected\"].sum()} spectra remaining in the library')\n",
    "    print(f'{len(df[\"NAME\"].unique())} compounds in the library')\n",
    "\n",
    "    # core adduct check\n",
    "    discarded_scan_ls, cmpd_adduct_to_be_removed_dict = core_adduct_check(df, core_adduct_ls=core_adduct_ls,\n",
    "                                                                          ms2_tol_da=ms2_tol_da,\n",
    "                                                                          modcos_score_cutoff=modcos_score_cutoff,\n",
    "                                                                          modcos_peak_cutoff=modcos_peak_cutoff)\n",
    "    df.loc[df['db_idx'].isin(discarded_scan_ls), 'selected'] = False\n",
    "    df.loc[df['db_idx'].isin(discarded_scan_ls), 'discard_reason'] = 'core_adduct_check'\n",
    "\n",
    "    print('After adduct check, ion dependency, mod cos match:')\n",
    "    print(f'{df[\"selected\"].sum()} spectra remaining in the library')\n",
    "    print(f'{len(df[\"NAME\"].unique())} compounds in the library')\n",
    "\n",
    "    # remove spectra, indicated by cmpd_adduct_to_be_removed_dict\n",
    "    df = isobaric_mass_adduct_check(df, cmpd_adduct_to_be_removed_dict)\n",
    "\n",
    "    print('After isobaric mass filter (unique adduct existence):')\n",
    "    print(f'{df[\"selected\"].sum()} spectra selected from the library')\n",
    "    print(f'{len(df[\"NAME\"].unique())} compounds in the library')\n",
    "\n",
    "    if write_df:\n",
    "        df.to_csv('output/filtered_library.tsv', sep='\\t', index=False)\n",
    "\n",
    "    # remove cols\n",
    "    df = df.drop(['_ADDUCT', '_NAME', 'db_idx', '_RT', 'NAME_1', 'NAME_2', 'conjugate', '_PEPMASS', 'cmpd_1_prec_int',\n",
    "                  'cmpd_2_prec_int', 'max_prec_int', 'discard_reason'], axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def write_to_mgf(df, out_mgf):\n",
    "    \"\"\"\n",
    "    Write the selected library to a new mgf file\n",
    "    \"\"\"\n",
    "    df = df[df['selected']].reset_index(drop=True)\n",
    "    # remove cols\n",
    "    df = df.drop(['selected'], axis=1)\n",
    "    # move cols mz_ls and intensity_ls to the end\n",
    "    df = df[[col for col in df.columns if col not in ['Num peaks', 'mz_ls', 'intensity_ls']] + ['Num peaks', 'mz_ls',\n",
    "                                                                                                'intensity_ls']]\n",
    "\n",
    "    with open(out_mgf, 'w') as file:\n",
    "        for idx, row in df.iterrows():\n",
    "            file.write('BEGIN IONS\\n')\n",
    "            for key, value in row.items():\n",
    "                if key == 'mz_ls':\n",
    "                    for mz, intensity in zip(row['mz_ls'], row['intensity_ls']):\n",
    "                        file.write(f'{mz} {intensity}\\n')\n",
    "                elif key == 'intensity_ls':\n",
    "                    continue\n",
    "                else:\n",
    "                    file.write(f'{key}={value}\\n')\n",
    "            file.write('END IONS\\n\\n')\n",
    "\n",
    "\n",
    "def write_tsv(df, library_tsv, out_tsv):\n",
    "    \"\"\"\n",
    "    Write the selected library to a new tsv file\n",
    "    \"\"\"\n",
    "    lib_tsv = pd.read_csv(f'input/{library_tsv}', sep='\\t')\n",
    "\n",
    "    # all SCANs selected\n",
    "    selected_scans = df[df['selected']]['SCANS'].tolist()\n",
    "\n",
    "    # reserve lib_tsv with selected scans in 'EXTRACTSCAN' column\n",
    "    lib_tsv = lib_tsv[lib_tsv['EXTRACTSCAN'].astype(str).isin(selected_scans)]\n",
    "    lib_tsv.to_csv(out_tsv, sep='\\t', index=False, na_rep='N/A')\n",
    "\n",
    "\n",
    "def precursor_check(df, cmpd_df_dict, ms2_tol_da, prec_intensity_cutoff=10):\n",
    "    \"\"\"\n",
    "    precursor existence check\n",
    "    this is to remove the spectra that are labeled incorrectly (one spectrum being selected multiple times)\n",
    "    \"\"\"\n",
    "    df['cmpd_1_prec_int'] = [None] * df.shape[0]\n",
    "    df['cmpd_2_prec_int'] = [None] * df.shape[0]\n",
    "    df['max_prec_int'] = [0] * df.shape[0]\n",
    "    for idx, row in df.iterrows():\n",
    "        if not row['conjugate']:\n",
    "            continue\n",
    "        if row['OTHER_MATCHED_COMPOUNDS'] is None:\n",
    "            continue\n",
    "\n",
    "        # get the precursor mz M+H of the two compounds\n",
    "        cmpd_1_prec_mz = cmpd_df_dict.get(row['NAME_1'])\n",
    "        cmpd_2_prec_mz = cmpd_df_dict.get(row['NAME_2'])\n",
    "        cmpd_1_prec_int = 0\n",
    "        cmpd_2_prec_int = 0\n",
    "        if cmpd_1_prec_mz:\n",
    "            mz_idx = np.argmin(np.abs(np.array(row['mz_ls']) - cmpd_1_prec_mz))\n",
    "            if np.abs(row['mz_ls'][mz_idx] - cmpd_1_prec_mz) <= ms2_tol_da:\n",
    "                cmpd_1_prec_int = row['intensity_ls'][mz_idx]\n",
    "                df.loc[idx, 'cmpd_1_prec_int'] = cmpd_1_prec_int\n",
    "        if cmpd_2_prec_mz:\n",
    "            mz_idx = np.argmin(np.abs(np.array(row['mz_ls']) - cmpd_2_prec_mz))\n",
    "            if np.abs(row['mz_ls'][mz_idx] - cmpd_2_prec_mz) <= ms2_tol_da:\n",
    "                cmpd_2_prec_int = row['intensity_ls'][mz_idx]\n",
    "                df.loc[idx, 'cmpd_2_prec_int'] = cmpd_2_prec_int\n",
    "\n",
    "        df.loc[idx, 'max_prec_int'] = max(cmpd_1_prec_int, cmpd_2_prec_int)\n",
    "\n",
    "    # sort df by _RT and _PEPMASS\n",
    "    df = df.sort_values(['_RT', '_PEPMASS'])\n",
    "    df['_PEPMASS'] = df['_PEPMASS'].astype(str)\n",
    "\n",
    "    _df = df[df['conjugate']]\n",
    "    discarded_scan_ls = []\n",
    "    for binned_rt in _df['_RT'].unique():\n",
    "        subdf = _df[_df['_RT'] == binned_rt]\n",
    "        # choose a subdf with the same precursor mz\n",
    "        for prec_mz in subdf['_PEPMASS'].unique():\n",
    "            _subdf = subdf[subdf['_PEPMASS'] == prec_mz]\n",
    "\n",
    "            if len(_subdf) == 1:\n",
    "                continue\n",
    "\n",
    "            # different compounds\n",
    "            if len(_subdf['_NAME'].unique()) == 1:\n",
    "                continue\n",
    "\n",
    "            # maximum precursor intensity\n",
    "            if _subdf['max_prec_int'].max() < prec_intensity_cutoff:\n",
    "                continue\n",
    "\n",
    "            # if multiple, sort by max_prec_int\n",
    "            _subdf = _subdf.sort_values('max_prec_int', ascending=False)\n",
    "\n",
    "            to_discard = _subdf[_subdf['max_prec_int'] == 0]['db_idx'].tolist()\n",
    "            discarded_scan_ls.extend(to_discard)\n",
    "\n",
    "    return discarded_scan_ls\n",
    "\n",
    "\n",
    "def core_adduct_check(df, core_adduct_ls=None,\n",
    "                      ms2_tol_da=0.05, modcos_score_cutoff=0.6, modcos_peak_cutoff=4):\n",
    "    df = df[df['selected']].copy()\n",
    "    # get the unique molecules\n",
    "    unique_smiles = df['SMILES'].unique().tolist()\n",
    "    # list of selected scan numbers\n",
    "    discarded_scan_ls = []\n",
    "    cmpd_adduct_to_be_removed_dict = {}  # key: RT, value: cmpd_adduct_to_be_removed\n",
    "    # filter the library by (SMILES, _RT)\n",
    "    for smiles in unique_smiles:\n",
    "        sub_df = df[(df['SMILES'] == smiles)]\n",
    "        for binned_rt in sub_df['_RT'].unique():\n",
    "            _subdf = sub_df[sub_df['_RT'] == binned_rt]\n",
    "\n",
    "            # check the subdf\n",
    "            scan_ls, cmpd_adduct_to_be_removed = subdf_check(_subdf, core_adduct_ls=core_adduct_ls,\n",
    "                                                             ms2_tol_da=ms2_tol_da,\n",
    "                                                             modcos_score_cutoff=modcos_score_cutoff,\n",
    "                                                             modcos_peak_cutoff=modcos_peak_cutoff)\n",
    "            discarded_scan_ls.extend(scan_ls)\n",
    "            if cmpd_adduct_to_be_removed:\n",
    "                cmpd_adduct_to_be_removed_dict[binned_rt] = cmpd_adduct_to_be_removed\n",
    "\n",
    "    return discarded_scan_ls, cmpd_adduct_to_be_removed_dict\n",
    "\n",
    "\n",
    "def subdf_check(df, core_adduct_ls=None,\n",
    "                ms2_tol_da=0.05, modcos_score_cutoff=0.6, modcos_peak_cutoff=4):\n",
    "    \"\"\"\n",
    "    check the dataframe for one molecule\n",
    "    :return: a list of selected scan numbers, a list of compound:adduct to be removed\n",
    "    \"\"\"\n",
    "    if core_adduct_ls is None:\n",
    "        core_adduct_ls = ['M+H', 'M-H2O+H', 'M+NH4', 'M-2H2O+H', 'M-H2O+NH4', 'M-2H2O+NH4', '2M+H',\n",
    "                          '2M-H2O+H', '2M+NH4', '2M-2H2O+H', '2M-H2O+NH4', '2M-2H2O+NH4', 'M-H']\n",
    "\n",
    "    # create a ModifiedCosine object\n",
    "    modified_cosine = ModifiedCosine(tolerance=ms2_tol_da)\n",
    "\n",
    "    subdf = df.copy()\n",
    "    # check the core adducts, if any adduct in the core_adduct_ls is in the library\n",
    "    subdf['core_adduct'] = subdf['_ADDUCT'].map(lambda x: x in core_adduct_ls)\n",
    "\n",
    "    # if no core adducts are found, return empty list\n",
    "    if not subdf['core_adduct'].any():\n",
    "        # print('No core adducts found: ', subdf['NAME'].iloc[0], '   Found adducts: ',\n",
    "        #       subdf['_ADDUCT'].unique().tolist())\n",
    "        return subdf['db_idx'].tolist(), []\n",
    "\n",
    "    # select the spectra with core adducts\n",
    "    core_df = subdf[subdf['core_adduct']].copy()\n",
    "    # sort by core_adduct_ls\n",
    "    core_df['core_adduct'] = core_df['_ADDUCT'].map(lambda x: core_adduct_ls.index(x))\n",
    "    core_df = core_df.sort_values('core_adduct')\n",
    "    # get all core spectra\n",
    "    core_spec_ls = []\n",
    "    for idx, row in core_df.iterrows():\n",
    "        core_spec = Spectrum(mz=np.array(row['mz_ls']),\n",
    "                             intensities=np.array(row['intensity_ls']),\n",
    "                             metadata={'precursor_mz': row['PEPMASS'],\n",
    "                                       'adduct': row['_ADDUCT']})\n",
    "        core_spec_ls.append(core_spec)\n",
    "\n",
    "    unique_adducts = subdf['_ADDUCT'].unique().tolist()\n",
    "    # check the adduct dependency\n",
    "    if len(unique_adducts) > 1:\n",
    "        allowed_adducts = unique_adducts.copy()\n",
    "        if 'M-H2O+Na' in unique_adducts and 'M-H2O+H' not in unique_adducts:\n",
    "            allowed_adducts.remove('M-H2O+Na')\n",
    "            if 'M-2H2O+Na' in allowed_adducts:\n",
    "                allowed_adducts.remove('M-2H2O+Na')\n",
    "            if 'M-3H2O+Na' in allowed_adducts:\n",
    "                allowed_adducts.remove('M-3H2O+Na')\n",
    "        if 'M-H2O+K' in unique_adducts and 'M-H2O+H' not in unique_adducts:\n",
    "            allowed_adducts.remove('M-H2O+K')\n",
    "            if 'M-2H2O+K' in allowed_adducts:\n",
    "                allowed_adducts.remove('M-2H2O+K')\n",
    "            if 'M-3H2O+K' in allowed_adducts:\n",
    "                allowed_adducts.remove('M-3H2O+K')\n",
    "        if 'M-2H2O+Na' in unique_adducts and 'M-H2O+Na' not in unique_adducts and 'M-2H2O+H' in unique_adducts:\n",
    "            allowed_adducts.remove('M-2H2O+Na')\n",
    "            if 'M-3H2O+Na' in allowed_adducts:\n",
    "                allowed_adducts.remove('M-3H2O+Na')\n",
    "        if 'M-2H2O+K' in unique_adducts and 'M-H2O+K' not in unique_adducts and 'M-2H2O+H' in unique_adducts:\n",
    "            allowed_adducts.remove('M-2H2O+K')\n",
    "            if 'M-3H2O+K' in allowed_adducts:\n",
    "                allowed_adducts.remove('M-3H2O+K')\n",
    "        if 'M-3H2O+Na' in unique_adducts and 'M-2H2O+Na' not in unique_adducts and 'M-3H2O+H' in unique_adducts:\n",
    "            allowed_adducts.remove('M-3H2O+Na')\n",
    "        if 'M-3H2O+K' in unique_adducts and 'M-2H2O+K' not in unique_adducts and 'M-3H2O+H' in unique_adducts:\n",
    "            allowed_adducts.remove('M-3H2O+K')\n",
    "        if 'M-2H2O+H' in unique_adducts and 'M-H2O+H' not in unique_adducts and 'M+H' in unique_adducts:\n",
    "            allowed_adducts.remove('M-2H2O+H')\n",
    "            if 'M-3H2O+H' in allowed_adducts:\n",
    "                allowed_adducts.remove('M-3H2O+H')\n",
    "        if 'M-3H2O+H' in unique_adducts and 'M-2H2O+H' not in unique_adducts and 'M+H' in unique_adducts:\n",
    "            allowed_adducts.remove('M-3H2O+H')\n",
    "        if 'M-2H2O+NH4' in unique_adducts and 'M-H2O+NH4' not in unique_adducts and 'M-2H2O+H' not in unique_adducts:\n",
    "            allowed_adducts.remove('M-2H2O+NH4')\n",
    "            if 'M-3H2O+NH4' in allowed_adducts:\n",
    "                allowed_adducts.remove('M-3H2O+NH4')\n",
    "        if 'M-3H2O+NH4' in unique_adducts and 'M-2H2O+NH4' not in unique_adducts and 'M-3H2O+H' not in unique_adducts:\n",
    "            allowed_adducts.remove('M-3H2O+NH4')\n",
    "\n",
    "        if '2M-H2O+Na' in unique_adducts and '2M-H2O+H' not in unique_adducts:\n",
    "            allowed_adducts.remove('2M-H2O+Na')\n",
    "            if '2M-2H2O+Na' in allowed_adducts:\n",
    "                allowed_adducts.remove('2M-2H2O+Na')\n",
    "            if '2M-3H2O+Na' in allowed_adducts:\n",
    "                allowed_adducts.remove('2M-3H2O+Na')\n",
    "        if '2M-H2O+K' in unique_adducts and '2M-H2O+H' not in unique_adducts:\n",
    "            allowed_adducts.remove('2M-H2O+K')\n",
    "            if '2M-2H2O+K' in allowed_adducts:\n",
    "                allowed_adducts.remove('2M-2H2O+K')\n",
    "            if '2M-3H2O+K' in allowed_adducts:\n",
    "                allowed_adducts.remove('2M-3H2O+K')\n",
    "        if '2M-2H2O+Na' in unique_adducts and '2M-H2O+Na' not in unique_adducts and '2M-2H2O+H' in unique_adducts:\n",
    "            allowed_adducts.remove('2M-2H2O+Na')\n",
    "            if '2M-3H2O+Na' in allowed_adducts:\n",
    "                allowed_adducts.remove('2M-3H2O+Na')\n",
    "        if '2M-2H2O+K' in unique_adducts and '2M-H2O+K' not in unique_adducts and '2M-2H2O+H' in unique_adducts:\n",
    "            allowed_adducts.remove('2M-2H2O+K')\n",
    "            if '2M-3H2O+K' in allowed_adducts:\n",
    "                allowed_adducts.remove('2M-3H2O+K')\n",
    "        if '2M-3H2O+Na' in unique_adducts and '2M-2H2O+Na' not in unique_adducts and '2M-3H2O+H' in unique_adducts:\n",
    "            allowed_adducts.remove('2M-3H2O+Na')\n",
    "        if '2M-3H2O+K' in unique_adducts and '2M-2H2O+K' not in unique_adducts and '2M-3H2O+H' in unique_adducts:\n",
    "            allowed_adducts.remove('2M-3H2O+K')\n",
    "        if '2M-2H2O+H' in unique_adducts and '2M-H2O+H' not in unique_adducts and '2M+H' in unique_adducts:\n",
    "            allowed_adducts.remove('2M-2H2O+H')\n",
    "            if '2M-3H2O+H' in allowed_adducts:\n",
    "                allowed_adducts.remove('2M-3H2O+H')\n",
    "        if '2M-3H2O+H' in unique_adducts and '2M-2H2O+H' not in unique_adducts and '2M+H' in unique_adducts:\n",
    "            allowed_adducts.remove('2M-3H2O+H')\n",
    "        if '2M-2H2O+NH4' in unique_adducts and '2M-H2O+NH4' not in unique_adducts and '2M-2H2O+H' not in unique_adducts:\n",
    "            allowed_adducts.remove('2M-2H2O+NH4')\n",
    "            if '2M-3H2O+NH4' in allowed_adducts:\n",
    "                allowed_adducts.remove('2M-3H2O+NH4')\n",
    "        if '2M-3H2O+NH4' in unique_adducts and '2M-2H2O+NH4' not in unique_adducts and '2M-3H2O+H' not in unique_adducts:\n",
    "            allowed_adducts.remove('2M-3H2O+NH4')\n",
    "\n",
    "        subdf['selected'] = subdf['_ADDUCT'].map(lambda x: x in allowed_adducts)\n",
    "\n",
    "        # for unselected spectra, calculate the scores for different adducts\n",
    "        for idx, row in subdf.iterrows():\n",
    "            if not row['selected']:\n",
    "                this_spec = Spectrum(mz=np.array(row['mz_ls']),\n",
    "                                     intensities=np.array(row['intensity_ls']),\n",
    "                                     metadata={'precursor_mz': row['PEPMASS'],\n",
    "                                               'adduct': row['_ADDUCT']})\n",
    "                # calculate the ModifiedCosine score\n",
    "                for core_spec in core_spec_ls:\n",
    "                    if core_spec.get('adduct') == this_spec.get('adduct'):\n",
    "                        continue\n",
    "                    score = modified_cosine.pair(core_spec, this_spec)\n",
    "                    if score['score'] >= modcos_score_cutoff or score['matches'] >= modcos_peak_cutoff:\n",
    "                        subdf.loc[idx, 'selected'] = True\n",
    "                        break\n",
    "\n",
    "        # use spectrum with unambiguous compound to filter out the ambiguous ones\n",
    "        cmpd_adduct_to_be_removed = None\n",
    "        _subdf = subdf[(subdf['selected']) & (subdf['OTHER_MATCHED_COMPOUNDS'].isna())]\n",
    "        if len(_subdf) > 0:\n",
    "            cmpd_adduct_to_be_removed = subdf['OTHER_MATCHED_COMPOUNDS_NAMES'].tolist()\n",
    "            # remove nan\n",
    "            cmpd_adduct_to_be_removed = [x for x in cmpd_adduct_to_be_removed if str(x) != 'nan']\n",
    "            # remove empty string\n",
    "            cmpd_adduct_to_be_removed = [x for x in cmpd_adduct_to_be_removed if x]\n",
    "            # split by ';' and flatten the list\n",
    "            cmpd_adduct_to_be_removed = [x.split(';') for x in cmpd_adduct_to_be_removed]\n",
    "            cmpd_adduct_to_be_removed = [item for sublist in cmpd_adduct_to_be_removed for item in sublist]\n",
    "\n",
    "        # db_idx of the discarded spectra\n",
    "        discarded_scan_no_ls = subdf[~subdf['selected']]['db_idx'].tolist()\n",
    "        return discarded_scan_no_ls, cmpd_adduct_to_be_removed\n",
    "    else:\n",
    "        return [], None\n",
    "\n",
    "\n",
    "def isobaric_mass_adduct_check(df, cmpd_adduct_to_be_removed_dict):\n",
    "    \"\"\"\n",
    "    isobaric mass filter, based on unique adduct existence\n",
    "    \"\"\"\n",
    "    if cmpd_adduct_to_be_removed_dict:\n",
    "        for binned_rt, cmpd_adduct_to_be_removed in cmpd_adduct_to_be_removed_dict.items():\n",
    "            for cmpd_adduct in cmpd_adduct_to_be_removed:\n",
    "                name, adduct, _ = cmpd_adduct.split(':')\n",
    "                row_idx = df[\n",
    "                    (df['_RT'] == binned_rt) & (df['NAME'] == name.strip()) & (df['ADDUCT'] == adduct.strip())].index\n",
    "                if len(row_idx) > 0:\n",
    "                    df.loc[row_idx, 'selected'] = False\n",
    "                    df.loc[row_idx, 'discard_reason'] = 'isobaric_mass_adduct_check'\n",
    "    return df\n",
    "\n",
    "\n",
    "def preprocess_cmpd_df(library_csv):\n",
    "    \"\"\"\n",
    "    Preprocess the compound dataframe, return a dictionary of compound name to precursor mass (M+H)\n",
    "    \"\"\"\n",
    "    cmpd_df = pd.read_csv(f'input/{library_csv}')\n",
    "\n",
    "    cmpd_df['prec_mz'] = cmpd_df['formula'].apply(calc_prec_mz)\n",
    "\n",
    "    # dictionary of mapping name to precursor mass\n",
    "    cmpd_df_dict = cmpd_df.set_index('compound_name')['prec_mz'].to_dict()\n",
    "\n",
    "    return cmpd_df_dict\n",
    "\n",
    "\n",
    "def calc_prec_mz(formula):\n",
    "    \"\"\"\n",
    "    Calculate the precursor mass (M+H) for a given formula string\n",
    "    \"\"\"\n",
    "    try:\n",
    "        f = Formula(formula)\n",
    "        return f.monoisotopic_mass + 1.007276\n",
    "    except:\n",
    "        return None\n"
   ],
   "id": "1aeb507d9b726b98",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T20:19:36.831367Z",
     "start_time": "2024-05-06T20:19:36.828668Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# name_sep: separator for the compound name. eg, 'Phe_CA' -> '_' is the separator\n",
    "name_sep = '_'"
   ],
   "id": "a0f3ceadcf321994",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T20:19:42.808315Z",
     "start_time": "2024-05-06T20:19:37.451207Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create the output folder\n",
    "if not os.path.exists('output'):\n",
    "    os.makedirs('output')\n",
    "\n",
    "# list all the files in the input folder\n",
    "all_files = os.listdir('input')\n",
    "# filter the mgf files\n",
    "library_mgfs = [x for x in all_files if x.endswith('.mgf')]\n",
    "\n",
    "for library_mgf in library_mgfs:\n",
    "    print(f'Processing {library_mgf}')\n",
    "\n",
    "    # check the existence of the .tsv\n",
    "    library_tsv = library_mgf.split('.mgf')[0] + '.tsv'\n",
    "    if not os.path.exists(f'input/{library_tsv}'):\n",
    "        print(f'tsv file missing: {library_tsv} does not exist')\n",
    "        continue\n",
    "\n",
    "    # check the existence of the .csv\n",
    "    library_csv = library_mgf.split('.mgf')[0] + '.csv'\n",
    "    if not os.path.exists(f'input/{library_csv}'):\n",
    "        print(f'csv file missing: {library_csv} does not exist')\n",
    "        continue\n",
    "    cmpd_df_dict = preprocess_cmpd_df(library_csv)\n",
    "\n",
    "    # main process\n",
    "    df = generate_library_df(library_mgf, name_sep)\n",
    "    df = select_library(df, cmpd_df_dict, ms2_tol_da=0.02, prec_intensity_cutoff=10,\n",
    "                        modcos_score_cutoff=0.6, modcos_peak_cutoff=4, write_df=True)\n",
    "\n",
    "    out_mgf = 'output/' + library_mgf.split('.mgf')[0] + '_filtered.mgf'\n",
    "    write_to_mgf(df, out_mgf)\n",
    "    out_tsv = 'output/' + library_tsv.split('.tsv')[0] + '_filtered.tsv'\n",
    "    write_tsv(df, library_tsv, out_tsv)"
   ],
   "id": "86c0242c5c09635f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 20240430_IM_BA_new_core_MZMine_libraryoutput_for_GNPS.mgf\n",
      "6984 spectra in the library\n",
      "After precursor existence check:\n",
      "6829 spectra remaining in the library\n",
      "1637 compounds in the library\n",
      "After adduct check, ion dependency, mod cos match:\n",
      "6080 spectra remaining in the library\n",
      "1637 compounds in the library\n",
      "After isobaric mass filter (unique adduct existence):\n",
      "5950 spectra selected from the library\n",
      "1637 compounds in the library\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "e055097d8cb0e2a3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
